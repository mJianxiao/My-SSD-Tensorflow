{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 视频转换图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally save 1909 pics\n"
     ]
    }
   ],
   "source": [
    "VIDEO_PATH = 'D:/0LT/chitanda/vedio/05.mkv' # 视频地址\n",
    "EXTRACT_FOLDER = 'D:/0LT/chitanda/vedio_pic/' # 存放帧图片的位置\n",
    "EXTRACT_FREQUENCY = 100 # 帧提取频率\n",
    "\n",
    "def extract_frames(video_path, dst_folder, index):\n",
    "    # 主操作\n",
    "    import cv2\n",
    "    video = cv2.VideoCapture()\n",
    "    if not video.open(video_path):\n",
    "        print(\"can not open the video\")\n",
    "        exit(1)\n",
    "    count = 1\n",
    "    while True:\n",
    "        _, frame = video.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "        if count % EXTRACT_FREQUENCY == 0:\n",
    "            save_path = \"{}/{:>04d}.jpg\".format(dst_folder, index)\n",
    "            cv2.imwrite(save_path, frame)\n",
    "            index += 1\n",
    "        count += 1\n",
    "    video.release()\n",
    "    # 打印出所提取帧的总数\n",
    "    print(\"Totally save {:d} pics\".format(index-1))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    extract_frames(VIDEO_PATH, EXTRACT_FOLDER, 1497)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 手动将不需要的图片删除，修改整理好后的图片名称（有序排列）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename()不能修改为已经有的名字，会报错\n",
    "当文件夹内有新旧（打过标签和未打标签）图片时，排序并非看起来的数字排序，所以可能未达标签的顺序可能比较靠前，使得重新命名的时候会命名为\n",
    "已经存在的名字，从而报错。\n",
    "所以最好将打过标签的图片存放在别的文件夹内，等这边的修改完再考进来（此时修改要记住命名的起点不是1）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 42 to rename & converted 858 jpgs\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "      \n",
    "class BatchRename():  \n",
    "        #批量重命名文件夹中的图片文件 \n",
    "        def __init__(self):  \n",
    "            self.path = 'D:/0LT/chitanda/VOC2007/JPEGImages/'  #图片文件夹路径\n",
    "      \n",
    "        def rename(self):  \n",
    "            filelist = os.listdir(self.path)  \n",
    "            total_num = len(filelist)  \n",
    "            i = 816  #从1开始排序\n",
    "            for item in filelist:  \n",
    "                if item.endswith('.jpg'):  \n",
    "                    n = 3 - len(str(i))  \n",
    "                    src = os.path.join(os.path.abspath(self.path), item)  \n",
    "                    dst = \"{}{:03d}.jpg\".format(self.path, i) \n",
    "                    try:  \n",
    "                        os.rename(src, dst)  \n",
    "                        i = i + 1 \n",
    "                    except:  \n",
    "                        print(src,dst)\n",
    "                        break  \n",
    "            print('total %d to rename & converted %d jpgs' % (total_num, i))  \n",
    "      \n",
    "if __name__ == '__main__':  \n",
    "        demo = BatchRename()  \n",
    "        demo.rename()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. labelimg给图片打上标签 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and val size 3081\n",
      "train size 2772\n",
      "test sizr 343\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "xmlfilepath = r'F:/Traing_folderV2/muck_car/Annotations/'\n",
    "saveBasePath = r'F:/Traing_folderV2/muck_car/ImageSets/'\n",
    "\n",
    "trainval_percent = 0.9\n",
    "train_percent = 0.9\n",
    "total_xml = os.listdir(xmlfilepath)\n",
    "num = len(total_xml)\n",
    "list = range(num)\n",
    "tv = int(num * trainval_percent)\n",
    "tr = int(tv * train_percent)\n",
    "trainval = random.sample(list, tv)\n",
    "train = random.sample(trainval, tr)\n",
    "\n",
    "print(\"train and val size\", tv)\n",
    "print(\"train size\", tr)\n",
    "print('test sizr',num-tv)\n",
    "ftrainval = open(os.path.join(saveBasePath, 'Main/trainval.txt'), 'w')\n",
    "ftest = open(os.path.join(saveBasePath, 'Main/test.txt'), 'w')\n",
    "ftrain = open(os.path.join(saveBasePath, 'Main/train.txt'), 'w')\n",
    "fval = open(os.path.join(saveBasePath, 'Main/val.txt'), 'w')\n",
    "\n",
    "for i in list:\n",
    "    name = total_xml[i][:-3] + '\\n'\n",
    "    if i in trainval:\n",
    "        ftrainval.write(name)\n",
    "        if i in train:\n",
    "            ftrain.write(name)\n",
    "        else:\n",
    "            fval.write(name)\n",
    "    else:\n",
    "        ftest.write(name)\n",
    "\n",
    "ftrainval.close()\n",
    "ftrain.close()\n",
    "fval.close()\n",
    "ftest.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 将图像数据修改tf格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 修改SSD-Tensorflow/datasets/pascalvoc_to_tfrecodes.py 的读取格式："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "image_data = tf.gfile.FastGFile(filename, 'rb').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 按照自己的数据集类型修改文件：SSD-Tensorflow/datasets/pascalvoc_common.py，示例如下： "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "VOC_LABELS = {\n",
    "    'none': (0, 'Background'),\n",
    "    'Chitanda': (1, 'People'),\n",
    "    'Oreki': (2, 'People'),\n",
    "    'Fukube': (3, 'People'),\n",
    "    'Ibara': (4, 'People'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 新建tfrecords_文件，保存tf格式的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 在pycharm里面运行tf_convert_data.py，输入如下参数.第一行和第三行不用更改，二四两行要改成绝对地址。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Dataset directory: F:/Traing_folderV2/muck_car/\n",
      "Output directory: F:/Traing_folderV2/muck_car/test/\n",
      ">> Converting image 1/3424WARNING:tensorflow:From F:\\Traing_folderV2\\SSD-Tensorflow-muck_car\\datasets\\pascalvoc_to_tfrecords.py:83: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      ">> Converting image 3424/3424\n",
      "Finished converting the Pascal VOC dataset!\n"
     ]
    }
   ],
   "source": [
    "%run tf_convert_data.py \\\n",
    "--dataset_name=pascalvoc \\\n",
    "--dataset_dir=F:/Traing_folderV2/muck_car/ \\\n",
    "--output_name=voc_2007_train \\\n",
    "--output_dir=F:/Traing_folderV2/muck_car/tfrecords_/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.训练模型 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 统计数据集的一些信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muck_car 2346 3109\n",
      "bus 1370 1679\n",
      "truck 1198 1418\n",
      "trailer 418 418\n",
      "total 3424 6624\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "Class = ['muck_car','bus','truck','trailer']\n",
    "annotation_folder =  r'F:/Traing_folderV2/muck_car/Annotations/'  # 改为自己标签文件夹的路径\n",
    "list = os.listdir(annotation_folder)\n",
    "def file_name(file_dir):\n",
    "    L = []\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1] == '.xml':\n",
    "                L.append(os.path.join(root, file))\n",
    "    return L\n",
    "total_Box = 0;total_Pic = 0\n",
    "box_num=[0 for i in range(len(Class))]\n",
    "pic_num=[0 for i in range(len(Class))]\n",
    "flag=[0 for i in range(len(Class))]\n",
    "\n",
    "xml_dirs = file_name(annotation_folder)\n",
    "\n",
    "for i in range(0, len(xml_dirs)):\n",
    "    #print(xml_dirs[i])\n",
    "    annotation_file = open(xml_dirs[i]).read()\n",
    "    root = ET.fromstring(annotation_file)\n",
    "    total_Pic += 1\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        for i in range(len(Class)):\n",
    "            if label == Class[i]:\n",
    "                box_num[i] += 1\n",
    "                flag[i] = 1\n",
    "                total_Box += 1\n",
    "    for i in range(len(Class)):\n",
    "        if flag[i] == 1:\n",
    "            pic_num[i] += 1\n",
    "            flag[i] = 0\n",
    "\n",
    "for i in range(len(Class)):\n",
    "    print(Class[i], pic_num[i], box_num[i])\n",
    "print(\"total\", total_Pic, total_Box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 按照上面的结果修改pascalvoc_2007.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TRAIN_STATISTICS = {\n",
    "    'none': (0, 0),\n",
    "    'car': (1567, 2027),\n",
    "    'people': (1003, 1413),\n",
    "    'red_youq': (1093, 1209),\n",
    "    'green_youq': (1450, 1452),\n",
    "    'total': (1613, 6101),\n",
    "}\n",
    "TEST_STATISTICS = {\n",
    "    'none': (0, 0),\n",
    "    'car': (1, 1),\n",
    "    'people': (1, 1),\n",
    "    'red_youq': (1, 1),\n",
    "    'green_youq': (1, 1),\n",
    "    'total': (4, 4),\n",
    "}\n",
    "SPLITS_TO_SIZES = {\n",
    "    'train': 1451,\n",
    "    'test': 162,\n",
    "}\n",
    "SPLITS_TO_STATISTICS = {\n",
    "    'train': TRAIN_STATISTICS,\n",
    "    'test': TEST_STATISTICS,\n",
    "}\n",
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 修改ssd_vgg_300.py     96，97行"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " num_classes=5,         #根据自己的数据修改为类别+1 \n",
    " no_annotation_label=5, #根据自己的数据修改为类别+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 修改eval_ssd_network.py    66行"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.app.flags.DEFINE_integer('num_classes', 5, 'Number of classes to use in the dataset.')   #类别+1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 修改 train_ssd_network.py     35，142，50-74，158，162 行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同上，在pycharm里面运行，train_ssd_network.py 输入如下参数，修改地址即可，其它酌情修改。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1从零开始"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%run train_ssd_network.py \n",
    "--train_dir=F:/Traing_folderV2/SSD-Tensorflow-youq_512/checkpoints/\n",
    "--dataset_dir=F:/Traing_folderV2/test/tfrecords_/\n",
    "--dataset_name=pascalvoc_2007\n",
    "--dataset_split_name=train\n",
    "--model_name=ssd_512_vgg\n",
    "--save_summaries_secs=1000\n",
    "--save_interval_secs=1000\n",
    "--optimizer=adam\n",
    "--learning_rate=0.005\n",
    "--learning_rate_decay_factor=0.95\n",
    "--batch_size=4\n",
    "--gpu_memory_fraction=0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#备注 batch_size不要过大，之前为32，会报错GPU内存不够，现改为8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2加载现有模型"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--train_dir=F:/Traing_folderV2/SSD-Tensorflow-myown/checkpoints/          \n",
    "--dataset_dir=F:/Traing_folderV2/temp/tfrecords_/\n",
    "--dataset_name=pascalvoc_2007\n",
    "--dataset_split_name=train\n",
    "--model_name=ssd_512_vgg\n",
    "--checkpoint_path=F:/Traing_folderV2/SSD-Tensorflow-myown/checkpoints/vgg_16.ckpt\n",
    "--checkpoint_model_scope=vgg_16\n",
    "--checkpoint_exclude_scopes=ssd_512_vgg/block7,ssd_512_vgg/block7_box,ssd_512_vgg/block8,ssd_512_vgg/block8_box,ssd_512_vgg/block9,ssd_512_vgg/block9_box,ssd_512_vgg/block10,ssd_512_vgg/block10_box,ssd_512_vgg/block11,ssd_512_vgg/block11_box,ssd_512_vgg/block12,ssd_512_vgg/block12_box\n",
    "--save_summaries_secs=1500\n",
    "--save_interval_secs=1500\n",
    "--weight_decay=0.0005  \n",
    "--optimizer=adam        \n",
    "--learning_rate=0.0001\n",
    "--learning_rate_decay_factor=0.90\n",
    "--batch_size=4\n",
    "--gpu_memory_fraction=0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *SSD原版验证代码需要解决以下问题：\n",
    "####     1.tf版本过高：\n",
    "#####       不用降低版本：./tf_extended/metrics.py中 51行，\"return variables.Variable\" =>> \"return variables.VariableV1\"\n",
    "\n",
    "#### 2.缺失flatten：\n",
    "##### 定义flatten()并修改327 和 346行：eval_op=list(...) => eval_op=flatten(list(...))；flatten()如下"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def flatten(x):\n",
    "    result=[]\n",
    "    for el in x:\n",
    "        if isinstance(el,tuple):\n",
    "            result.extend(flatten(el))\n",
    "        else:\n",
    "            result.append(el)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 生成验证数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Dataset directory: F:/Traing_folderV2/test/\n",
      "Output directory: F:/Traing_folderV2/test/tfrecords_/\n",
      ">> Converting image 1/116WARNING:tensorflow:From F:\\Traing_folderV2\\SSD-Tensorflow-muck_car\\datasets\\pascalvoc_to_tfrecords.py:83: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      ">> Converting image 116/116\n",
      "Finished converting the Pascal VOC dataset!\n"
     ]
    }
   ],
   "source": [
    "%run tf_convert_data.py \\\n",
    "--dataset_name=pascalvoc \\\n",
    "--dataset_dir=F:/Traing_folderV2/test/ \\\n",
    "--output_name=voc_2007_test \\\n",
    "--output_dir=F:/Traing_folderV2/test/tfrecords_/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 运行验证代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Traing_folderV2\\SSD-Tensorflow-muck_car\\eval_ssd_network.py:122: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "# =========================================================================== #\n",
      "# Training | Evaluation flags:\n",
      "# =========================================================================== #\n",
      "{'batch_size': <absl.flags._flag.Flag object at 0x000000001108A8C8>,\n",
      " 'checkpoint_path': <absl.flags._flag.Flag object at 0x000000001108AF88>,\n",
      " 'dataset_dir': <absl.flags._flag.Flag object at 0x000000001108D4C8>,\n",
      " 'dataset_name': <absl.flags._flag.Flag object at 0x000000001108D2C8>,\n",
      " 'dataset_split_name': <absl.flags._flag.Flag object at 0x000000001108D3C8>,\n",
      " 'eval_dir': <absl.flags._flag.Flag object at 0x000000001108D0C8>,\n",
      " 'eval_image_size': <absl.flags._flag.Flag object at 0x000000001108AA88>,\n",
      " 'eval_resize': <absl.flags._flag.Flag object at 0x000000001108A988>,\n",
      " 'gpu_memory_fraction': <absl.flags._flag.Flag object at 0x000000001108D808>,\n",
      " 'h': <tensorflow.python.platform.app._HelpFlag object at 0x000000001108D988>,\n",
      " 'help': <tensorflow.python.platform.app._HelpFlag object at 0x000000001108D988>,\n",
      " 'helpfull': <tensorflow.python.platform.app._HelpfullFlag object at 0x000000001108DA88>,\n",
      " 'helpshort': <tensorflow.python.platform.app._HelpshortFlag object at 0x000000001108DB88>,\n",
      " 'keep_top_k': <absl.flags._flag.Flag object at 0x000000001108A648>,\n",
      " 'master': <absl.flags._flag.Flag object at 0x000000001108AE88>,\n",
      " 'matching_threshold': <absl.flags._flag.Flag object at 0x000000001108A808>,\n",
      " 'max_num_batches': <absl.flags._flag.Flag object at 0x000000001108ADC8>,\n",
      " 'model_name': <absl.flags._flag.Flag object at 0x000000001108D588>,\n",
      " 'moving_average_decay': <absl.flags._flag.Flag object at 0x000000001108D748>,\n",
      " 'nms_threshold': <absl.flags._flag.Flag object at 0x000000001108A708>,\n",
      " 'num_classes': <absl.flags._flag.Flag object at 0x000000001108AC48>,\n",
      " 'num_preprocessing_threads': <absl.flags._flag.Flag object at 0x000000001108D1C8>,\n",
      " 'preprocessing_name': <absl.flags._flag.Flag object at 0x000000001108D688>,\n",
      " 'remove_difficult': <absl.flags._flag.BooleanFlag object at 0x000000001108AB08>,\n",
      " 'select_threshold': <absl.flags._flag.Flag object at 0x0000000011051E48>,\n",
      " 'select_top_k': <absl.flags._flag.Flag object at 0x000000001107EF08>,\n",
      " 'wait_for_checkpoints': <absl.flags._flag.BooleanFlag object at 0x000000001108D8C8>}\n",
      "\n",
      "# =========================================================================== #\n",
      "# SSD net parameters:\n",
      "# =========================================================================== #\n",
      "{'anchor_offset': 0.5,\n",
      " 'anchor_ratios': [[2, 0.5],\n",
      "                   [2, 0.5, 3, 0.3333333333333333],\n",
      "                   [2, 0.5, 3, 0.3333333333333333],\n",
      "                   [2, 0.5, 3, 0.3333333333333333],\n",
      "                   [2, 0.5, 3, 0.3333333333333333],\n",
      "                   [2, 0.5],\n",
      "                   [2, 0.5]],\n",
      " 'anchor_size_bounds': [0.1, 0.9],\n",
      " 'anchor_sizes': [(20.48, 51.2),\n",
      "                  (51.2, 133.12),\n",
      "                  (133.12, 215.04),\n",
      "                  (215.04, 296.96),\n",
      "                  (296.96, 378.88),\n",
      "                  (378.88, 460.8),\n",
      "                  (460.8, 542.72)],\n",
      " 'anchor_steps': [8, 16, 32, 64, 128, 256, 512],\n",
      " 'feat_layers': ['block4',\n",
      "                 'block7',\n",
      "                 'block8',\n",
      "                 'block9',\n",
      "                 'block10',\n",
      "                 'block11',\n",
      "                 'block12'],\n",
      " 'feat_shapes': [(64, 64), (32, 32), (16, 16), (8, 8), (4, 4), (2, 2), (1, 1)],\n",
      " 'img_shape': (512, 512),\n",
      " 'no_annotation_label': 5,\n",
      " 'normalizations': [20, -1, -1, -1, -1, -1, -1],\n",
      " 'num_classes': 5,\n",
      " 'prior_scaling': [0.1, 0.1, 0.2, 0.2]}\n",
      "\n",
      "# =========================================================================== #\n",
      "# Training | Evaluation dataset files:\n",
      "# =========================================================================== #\n",
      "['F:\\\\Traing_folderV2\\\\test\\\\tfrecords_\\\\voc_2007_test_000.tfrecord']\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\data\\parallel_reader.py:242: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\data\\parallel_reader.py:94: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From F:\\Traing_folderV2\\SSD-Tensorflow-muck_car\\nets\\ssd_common.py:77: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From F:\\Traing_folderV2\\SSD-Tensorflow-muck_car\\eval_ssd_network.py:185: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From F:\\Traing_folderV2\\SSD-Tensorflow-muck_car\\eval_ssd_network.py:235: streaming_mean (from tensorflow.contrib.metrics.python.ops.metric_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.metrics.mean\n",
      "WARNING:tensorflow:From F:\\Traing_folderV2\\SSD-Tensorflow-muck_car\\tf_extended\\metrics.py:159: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From F:\\Traing_folderV2\\SSD-Tensorflow-muck_car\\eval_ssd_network.py:281: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
      "Instructions for updating:\n",
      "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
      "```python\n",
      "    sess = tf.Session()\n",
      "    with sess.as_default():\n",
      "        tensor = tf.range(10)\n",
      "        print_op = tf.print(tensor)\n",
      "        with tf.control_dependencies([print_op]):\n",
      "          out = tf.add(tensor, tensor)\n",
      "        sess.run(out)\n",
      "    ```\n",
      "Additionally, to use tf.print in python 2.7, users must make sure to import\n",
      "the following:\n",
      "\n",
      "  `from __future__ import print_function`\n",
      "\n",
      "INFO:tensorflow:Evaluating F:/Traing_folderV2/SSD-Tensorflow-muck_car/checkpoints/model.ckpt-79239\n",
      "INFO:tensorflow:Starting evaluation at 2020-03-03T06:07:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from F:/Traing_folderV2/SSD-Tensorflow-muck_car/checkpoints/model.ckpt-79239\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Evaluation [23/230]\n",
      "INFO:tensorflow:Evaluation [46/230]\n",
      "INFO:tensorflow:Evaluation [69/230]\n",
      "INFO:tensorflow:Evaluation [92/230]\n",
      "INFO:tensorflow:Evaluation [115/230]\n",
      "INFO:tensorflow:Evaluation [138/230]\n",
      "INFO:tensorflow:Evaluation [161/230]\n",
      "INFO:tensorflow:Evaluation [184/230]\n",
      "INFO:tensorflow:Evaluation [207/230]\n",
      "INFO:tensorflow:Evaluation [230/230]\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-03-06:22:33\n",
      "Time spent : 911.208 seconds.\n",
      "Time spent per BATCH: 3.962 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run eval_ssd_network.py \\\n",
    "--eval_dir=F:/Traing_folderV2/SSD-Tensorflow-muck_car/eval_log/ \\\n",
    "--dataset_dir=F:/Traing_folderV2/test/tfrecords_/ \\\n",
    "--dataset_name=pascalvoc_2007 \\\n",
    "--dataset_split_name=test \\\n",
    "--model_name=ssd_512_vgg \\\n",
    "--checkpoint_path=F:/Traing_folderV2/SSD-Tensorflow-muck_car/checkpoints/model.ckpt-79239 \\\n",
    "--batch_size=1 \\\n",
    "--select_threshold=0.8 \\\n",
    "--nms_threshold=0.1 \\\n",
    "--matching_threshold=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "9999899999900001\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "s=99999999999*99999\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
